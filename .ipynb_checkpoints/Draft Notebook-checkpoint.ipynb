{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import cv2\n",
    "from random import shuffle \n",
    "from tqdm import tqdm \n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Testing File path\n",
    "Image.open('data/chest_xray/train/NORMAL/IM-0115-0001.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['PNEUMONIA', 'NORMAL']\n",
    "img_size = 210\n",
    "def get_data(data_dir):\n",
    "    data = [] \n",
    "    for label in tqdm(labels): \n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = get_data('data/chest_xray/train/')\n",
    "test_path = get_data('data/chest_xray/test/')\n",
    "val_path = get_data('data/chest_xray/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = []\n",
    "for i in train_path:\n",
    "    if(i[1] == 0):\n",
    "        mask.append(\"Pneumonia\")\n",
    "    else:\n",
    "        mask.append(\"Normal\")\n",
    "sns.countplot(mask);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for image, label in train_path:\n",
    "    X_train.append(image)\n",
    "    y_train.append(label)\n",
    "\n",
    "for image, label in test_path:\n",
    "    X_test.append(image)\n",
    "    y_test.append(label)\n",
    "    \n",
    "for image, label in val_path:\n",
    "    X_val.append(image)\n",
    "    y_val.append(label)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "X_train = np.array(X_train) / 255\n",
    "X_val = np.array(X_val) / 255\n",
    "X_test = np.array(X_test) / 255\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(5216, 32400).astype('float32')\n",
    "X_test = X_test.reshape(624, 32400).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression(penalty='l2')\n",
    "log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, 2)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='tanh', input_shape=(32400,)))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#param_grid = {\n",
    "    'n_estimators': [25,100,250],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [1, 2, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10, 20]\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier(random_state=777)\n",
    "\n",
    "#gs_forest = GridSearchCV(model, param_grid, cv=3)\n",
    "#gs_forest.fit(X_train,y_train)\n",
    "#gs_forest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#great lets do it again with more params based on the ones it picked\n",
    "\n",
    "#param_grid = {\n",
    "    'n_estimators': [250,350,500],\n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth': [10,15,25,100],\n",
    "    'min_samples_split': [2,5]\n",
    "}\n",
    "\n",
    "#gs_forest = GridSearchCV(model, param_grid, cv=3)\n",
    "#gs_forest.fit(X_train,y_train)\n",
    "#gs_forest.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets actually model now\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(criterion= 'entropy', max_depth= 15, min_samples_split= 5, \n",
    "                               n_estimators= 500, random_state=777)\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playing with weights\n",
    "\n",
    "weights = [{0: 1, 1: 3}, {0: 1, 1: 1}]\n",
    "\n",
    "model = RandomForestClassifier(criterion= 'entropy', max_depth= 15, min_samples_split= 5, \n",
    "                               n_estimators= 700, random_state=777,class_weight=weights)\n",
    "model.fit(X_train,y_train)\n",
    "print(model.score(X_train, y_train))\n",
    "print(model.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#increasing the depbths cause google told me too, but only a little cause our GS said 15 was better than 25, so we trying 20\n",
    "\n",
    "model = RandomForestClassifier(criterion= 'entropy', max_depth= 20, min_samples_split= 5, \n",
    "                               n_estimators= 700, random_state=777,class_weight=weights)\n",
    "model.fit(X_train,y_train)\n",
    "print(cross_val_score(model, X_test, y_test, cv=5))\n",
    "print(model.score(X_train, y_train))\n",
    "print(model.score(X_test,y_test))\n",
    "# Seems that made it  little worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying adding a max features limiter\n",
    "model = RandomForestClassifier(criterion= 'entropy', max_depth= 15, min_samples_split= 5, \n",
    "                               n_estimators= 700, random_state=777,max_features='log2')\n",
    "model.fit(X_train,y_train)\n",
    "print(cross_val_score(model, X_test, y_test, cv=5))\n",
    "print(model.score(X_train, y_train))\n",
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying adding a max features limiter\n",
    "model = RandomForestClassifier(criterion= 'entropy', max_depth= 15, min_samples_split= 5, \n",
    "                               n_estimators= 700, random_state=777,max_features='sqrt')\n",
    "model.fit(X_train,y_train)\n",
    "print(cross_val_score(model, X_test, y_test, cv=5))\n",
    "print(model.score(X_train, y_train))\n",
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('they each get worse idk what to do')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
